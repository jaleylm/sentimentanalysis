##same for second stock:

    # Input in the variable "phrase", the name of the stock chosen + adding the word stock to get every finance-related article
    phrase = str(selection2.get()) + " stock"

    # Adding my unique APIKey found by creating an account in the API 'newsapi-python"
    newsapi = NewsApiClient(api_key='f704389a97e24101834d34232a5da98d')
    my_date = date.today() - timedelta(days=7)

    # Restricting the list to 10 articles to be more visible
    articles = newsapi.get_everything(q=phrase,
                                      from_param=my_date.isoformat(),
                                      language="en",
                                      sort_by="relevancy",
                                      page_size=10)

    # Printing all article summaries thanks to this loop, with their title + their publishing time + their ULR
    for article in articles['articles']:
        print(article['title'] + ' | ' + article['publishedAt'] + ' | ' + article['url'])

    ## Sentiments Analysis
    sia = SentimentIntensityAnalyzer()

    # Setting the display size
    pd.set_option('display.max_colwidth', 1000)

    # Define a variable "get_sources", by linking my APIKey in order to connect the program to this API
    def get_sources(category=None):
        url = 'https://newsapi.org/v2/everything?'
        newsapi = NewsApiClient(api_key='f704389a97e24101834d34232a5da98d')
        sources = newsapi.get_sources()

        # Explaining that if there is no particular category for the sources, ...
        # ... it will look for every possible articles in english, otherwise it will only focus on a sector defined like "business" for our case
        if category is not None:
            rez = [source['id'] for source in sources['sources'] if
                   source['category'] == category and source['language'] == 'en']
        else:
            rez = [source['id'] for source in sources['sources'] if source['language'] == 'en']
        return rez

    # Not relevant for the program, but it shows the number of category we can choose to focus on
    len(get_sources())

    # Showing us the newspapers in which our program will look into
    get_sources('business')

    # Creating the variable below, acting according to : the name of the stock + the source category + telling it not to print every articles
    def get_articles_sentiments(keywrd, startd, sources_list=None, show_all_articles=False):
        newsapi = NewsApiClient(api_key='f704389a97e24101834d34232a5da98d')
        # Indicating the date is  this day thanks to the module datetime
        if type(startd) == str:
            my_date = datetime.strptime(startd, '%d-%b-%Y')
        else:
            my_date = startd
        # If the sources list is provided we have to use it,
        if sources_list:
            articles = newsapi.get_everything(q=keywrd, from_param=my_date.isoformat(),
                                              to=(my_date + timedelta(days=1)).isoformat(), language="en",
                                              sources=",".join(sources_list), sort_by="relevancy", page_size=100)
        else:
            articles = newsapi.get_everything(q=keywrd, from_param=my_date.isoformat(),
                                              to=(my_date + timedelta(days=1)).isoformat(), language="en",
                                              sort_by="relevancy", page_size=100)

        article_content = ''

        date_sentiments = {}
        date_sentiments_list = []
        seen = set()

        for article in articles['articles']:
            if str(article['title']) in seen:
                continue
            else:
                seen.add(str(article['title']))
                article_content = str(article['title']) + '. ' + str(article['description'])
                # Calculating the sentiment score by compounding the scores
                sentiment = sia.polarity_scores(article_content)['compound']

                date_sentiments.setdefault(my_date, []).append(sentiment)
                date_sentiments_list.append((sentiment, article['url'], article['title'], article['description']))

        date_sentiments_l = sorted(date_sentiments_list, key=lambda tup: tup[0], reverse=True)
        sent_list = list(date_sentiments.values())[0]

        # Return a dataframe with all sentiment scores and articles
        return pd.DataFrame(date_sentiments_list, columns=['Sentiment', 'URL', 'Title', 'Description'])

    ## Printing Analysis (Mean + Chart)
    sources = get_sources('business')
    return_articles = get_articles_sentiments(selection2.get(), startd='24-Nov-2022', sources_list=sources, show_all_articles=True)

    ##  Printing sentiments analysis by order, #need to use old variable return_articles not return_articles2
    return_articles.sort_values(by='Sentiment', ascending=True)[['Sentiment', 'URL', 'Description', 'Title']].head(3)
    return_articles.sort_values(by='Sentiment', ascending=False)[['Sentiment', 'URL', 'Description', 'Title']].head(3)

    ## Sentiment for a bunch of general stocks
    # Indicating the variable to look only for articles in the business sector (previously defined by "sources"), since 24/11/2022.
    return_articles2 = get_articles_sentiments(selection2.get(), '24-Nov-2022', sources_list=sources, show_all_articles=True)

    # Printing the economic sentiment mean (with only 4 decimals) thanks to the "return_articles.Sentiment.mean" variable
    print("The economic sentiment since the 1st November has a mean of : " + str(return_articles2.Sentiment.mean())[:6] + " according to the articles")

    # Printing with how many articles this variable has been calculated
    print("This mean has been calculated in a bunch of " + str(return_articles2.Sentiment.count()) + " aricles")
